# PsychoPortal

**Self-evolving AI personal assistant with a persistent knowledge graph.**

> Remembers everything. Learns from mistakes. Gets smarter every session.

---

## What It Does

PsychoPortal is a local-first AI assistant that:

- **Builds its own knowledge graph** from your conversations â€” entities, relationships, facts â€” all structured and searchable
- **Learns from mistakes** â€” when you correct it, it updates its confidence scores and avoids the same error in future sessions
- **Persists memory across sessions** â€” everything you discuss is remembered and used as context in future conversations
- **Works with any LLM** â€” Anthropic Claude (API) or any local model via Ollama
- **Runs entirely on your machine** â€” no cloud required except for the API key

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PSYCHO PORTAL                              â”‚
â”‚                                                              â”‚
â”‚  CLI Dashboard (Rich + prompt_toolkit)                       â”‚
â”‚         â†“                                                    â”‚
â”‚  Agent Core (perceive â†’ think â†’ act â†’ learn)                 â”‚
â”‚         â†“                      â†“                             â”‚
â”‚  LLM Provider             Memory Manager                     â”‚
â”‚  (Anthropic / Ollama)     (Short + Long + Semantic)          â”‚
â”‚         â†“                      â†“                             â”‚
â”‚                        Knowledge Graph                       â”‚
â”‚                        (NetworkX + ChromaDB)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Self-Evolution Loop

```
Interaction
    â†“
Extract entities & relationships (LLM-powered)
    â†“
Update knowledge graph (confidence-weighted)
    â†“
Post-session reflection (synthesize, infer, prune)
    â†“
Next session is smarter
```

## Phases

| Phase | Status | Description |
|-------|--------|-------------|
| 1 | âœ… Current | Foundation: agent, memory, CLI dashboard |
| 2 | ğŸ”œ Next | Semantic memory (ChromaDB) + Ollama |
| 3 | ğŸ“‹ Planned | Knowledge graph (NetworkX) |
| 4 | ğŸ“‹ Planned | Self-evolution engine (reflection, confidence) |
| 5 | ğŸ“‹ Planned | Domain intelligence (coding, health, tasks) |
| 6 | ğŸ“‹ Planned | FastAPI server + web UI |

## Quick Start

### 1. Install Python 3.11+

### 2. Clone and set up

```bash
git clone https://github.com/YOUR_USERNAME/psycho_portal
cd psycho_portal
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configure

```bash
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
```

### 4. Run

```bash
# Interactive chat with dashboard
python main.py chat

# View memory statistics
python main.py stats

# Start API server (Phase 6)
python main.py serve
```

## Configuration

All configuration lives in `.env`:

```env
# LLM Provider: "anthropic" or "ollama"
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-haiku-4-5-20251001  # cheapest/fastest

# For local (no API key needed):
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama3.2
```

## CLI Commands

| Command | Description |
|---------|-------------|
| `python main.py chat` | Start interactive chat |
| `python main.py stats` | Memory & session stats |
| `python main.py serve` | HTTP API server |

### In-chat commands

| Command | Description |
|---------|-------------|
| `/help` | Show all commands |
| `/stats` | Session statistics |
| `/facts` | List stored facts |
| `/clear` | Clear screen |
| `exit` / `quit` | Exit chat |

## Data

All personal data is stored in `data/` (gitignored):

```
data/
â”œâ”€â”€ psycho.db           # SQLite: conversations, facts, preferences
â”œâ”€â”€ graph/              # Knowledge graph (Phase 3)
â”œâ”€â”€ vectors/            # ChromaDB embeddings (Phase 2)
â””â”€â”€ journals/           # Session reflection logs (Phase 4)
```

## Tech Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| Language | Python 3.11+ | Best AI/ML ecosystem |
| LLM (API) | Anthropic Claude Haiku | Cheapest capable model |
| LLM (local) | Ollama | Zero-cost local inference |
| Knowledge graph | NetworkX | In-process, JSON serializable, zero infrastructure |
| Vector store | ChromaDB | Local, no Docker, pluggable embeddings |
| Database | SQLite + aiosqlite | Zero setup, async, fully capable |
| CLI | Rich + Click + prompt_toolkit | Beautiful terminal, input with history |
| Config | pydantic-settings | Typed, validated, .env-backed |

## License

MIT
